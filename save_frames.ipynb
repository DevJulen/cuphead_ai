{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for saving annotated frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "GPUs: 1\n",
      "GPU name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keyboard\n",
    "import uuid\n",
    "import os\n",
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Is CUDA available: %s\" % torch.cuda.is_available()) \n",
    "print(\"GPUs: %s\" % torch.cuda.device_count()) \n",
    "print(\"GPU name: %s\" % torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\julen/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-4-17 Python-3.9.13 torch-1.8.2+cu111 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\julen\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True) # pre-trained YOLOv5-XL version\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/first_weights.pt', force_reload=True) # weights after the first training\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/final_weights.pt', force_reload=True) # weights after the second training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving images from a video every x seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images\n",
      "Q pressed, exiting\n"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = 'data/images/' # path for saving the images\n",
    "SEC = .5 # save two frames every second\n",
    "FPS = 60 # frame rate\n",
    "\n",
    "count = 0\n",
    "\n",
    "keyboard.wait('s') # wait for the 's' key to be pressed to start\n",
    "print(\"Saving images\")\n",
    "while True:\n",
    "    hwnd = win32gui.FindWindow(None, \"Cuphead\") # find the game's window\n",
    "    rect = win32gui.GetWindowPlacement(hwnd)[-1]\n",
    "    image = ImageGrab.grab(rect)\n",
    "    file_name = uuid.uuid1() # create unique identifier for each of the file names\n",
    "    \n",
    "    if count%(SEC*FPS) == 0:\n",
    "        cv2.imwrite(os.path.join(IMAGES_PATH,\"%d.jpg\" % file_name), cv2.cvtColor(np.array(image),cv2.COLOR_BGR2RGB)) # save frame as JPG file\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    if keyboard.is_pressed(\"q\"):\n",
    "        print(\"Q pressed, exiting\")\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second filter for getting anotated images based on the first training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the YOLO output results converts and returns those results in the YOLO input format:\n",
    "class_num: class value\n",
    "x: x coordinate of the detection b-box center\n",
    "y: y coordinate of the detection b-box center\n",
    "w: width of the detection b-box\n",
    "h: height of the detection b-box\n",
    "\n",
    "Detections will be filtered to remove the ones with a low area\n",
    "\n",
    "Except for the class value, all other values will be normalized\n",
    "\"\"\"\n",
    "def filter2(results):\n",
    "    CLASSES = [0, 1]\n",
    "\n",
    "    # convert to dataframe\n",
    "    res_fil = results.pandas().xyxy[0]\n",
    "\n",
    "    # filter the detections with a confidence over 0.29, and unwanted detections\n",
    "    res_fil = res_fil.loc[(res_fil['confidence']>0.29) & ((res_fil['class'].isin(CLASSES)))] \n",
    "\n",
    "    aux = pd.DataFrame()\n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    # check each row looking for overlaping bounding boxes\n",
    "    for _, row1 in res_fil.iterrows():\n",
    "        min_row = pd.DataFrame()\n",
    "        for _, row2 in res_fil.iterrows():\n",
    "            if((abs(row1['xmin']-row2['xmin']) > 0) and (abs(row1['ymin']-row2['ymin']) > 0)\n",
    "            and (abs(row1['xmax']-row2['xmax']) > 0) and (abs(row1['ymax']-row2['ymax']) > 0)\n",
    "            and (abs(row1['xmin']-row2['xmin']) <= 100) and (abs(row1['ymin']-row2['ymin']) <= 100)\n",
    "            and (abs(row1['xmax']-row2['xmax']) <= 100) and (abs(row1['ymax']-row2['ymax']) <= 100)):\n",
    "                if(row2['confidence'] >= row1['confidence']):\n",
    "                    min_row = row1.T\n",
    "        if(len(min_row) > 0):\n",
    "            aux = pd.concat([aux, min_row.T], ignore_index=False)\n",
    "        \n",
    "    # get the difference to remove the overlapinng bounding boxes\n",
    "    res = pd.concat([res_fil, aux.T]).drop_duplicates(keep=False)\n",
    "\n",
    "    \n",
    "    # compute the input-format values\n",
    "    xmax = res.xmax.astype(float)\n",
    "    xmin = res.xmin.astype(float)\n",
    "    ymax = res.ymax.astype(float)\n",
    "    ymin = res.ymin.astype(float)\n",
    "    \n",
    "    class_num = list(res[\"class\"].astype(int))\n",
    "\n",
    "    x = list(((xmax+xmin)/2)/1920)\n",
    "    y = list(((ymax+ymin)/2)/1080)\n",
    "    w = list((xmax-xmin)/1920)\n",
    "    h = list((ymax-ymin)/1080)\n",
    "\n",
    "    x_res = [] \n",
    "    y_res = []\n",
    "    w_res = []\n",
    "    h_res = []\n",
    "    class_num_res = []\n",
    "\n",
    "    # get only the detection bounding boxes with an area over 0.008 so that we only get the detections of the actual cuphead\n",
    "    if(len(class_num) > 0):\n",
    "        for x1, y1, w1, h1, class1 in zip(x, y, w, h, class_num):\n",
    "            if((w1*h1) > 0.007):\n",
    "                x_res.append(x1) \n",
    "                y_res.append(y1)\n",
    "                w_res.append(w1)\n",
    "                h_res.append(h1)\n",
    "                class_num_res.append(class1)\n",
    "\n",
    "    return class_num_res, x_res, y_res, w_res, h_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to convert detection results to the YOLO input format for anotating goopy and cuphead images using the YOLOv5-XL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the YOLO output results converts and returns those results in the YOLO input format:\n",
    "class_num: class value\n",
    "x: x coordinate of the detection b-box center\n",
    "y: y coordinate of the detection b-box center\n",
    "w: width of the detection b-box\n",
    "h: height of the detection b-box\n",
    "\n",
    "Detections will be filtered to remove the irrelevant classes and duplicated detections\n",
    "\n",
    "Except for the class value, all other values will be normalized\n",
    "\"\"\"\n",
    "def filter(results, level):\n",
    "\n",
    "    if(level != 0):\n",
    "        return filter2(results)\n",
    "    else:\n",
    "        # most common classes detected by YOLO for each object\n",
    "        # [0: person, 1: bicycle, 3: motorcycle, 13: bench]\n",
    "        CUPHEAD_CLASSES = [0, 1, 3, 13] \n",
    "\n",
    "        # [14: bird, 29: frisbee, 32: sports ball, 37: surfboard, 45: bowl,\n",
    "        #  55: cake, 70: toaster, 74: clock, 75: vase]\n",
    "        GOOPY_CLASSES = [14, 29, 32, 33, 37, 45, 55, 70, 74, 75]\n",
    "\n",
    "        # convert to dataframe\n",
    "        res_fil = results.pandas().xyxy[0]\n",
    "\n",
    "        # filter the detections with a confidence over 0.39, and unwanted detections\n",
    "        res_fil = res_fil.loc[(res_fil['confidence']>0.39) & ((res_fil['class'].isin(CUPHEAD_CLASSES)) | (res_fil['class'].isin(GOOPY_CLASSES)))] \n",
    "\n",
    "        aux = pd.DataFrame()\n",
    "        res = pd.DataFrame()\n",
    "\n",
    "        # check each row looking for overlaping bounding boxes\n",
    "        for _, row1 in res_fil.iterrows():\n",
    "            min_row = pd.DataFrame()\n",
    "            for _, row2 in res_fil.iterrows():\n",
    "                if((abs(row1['xmin']-row2['xmin']) > 0) and (abs(row1['ymin']-row2['ymin']) > 0)\n",
    "                and (abs(row1['xmax']-row2['xmax']) > 0) and (abs(row1['ymax']-row2['ymax']) > 0)\n",
    "                and (abs(row1['xmin']-row2['xmin']) <= 100) and (abs(row1['ymin']-row2['ymin']) <= 100)\n",
    "                and (abs(row1['xmax']-row2['xmax']) <= 100) and (abs(row1['ymax']-row2['ymax']) <= 100)):\n",
    "                    if(row2['confidence'] >= row1['confidence']):\n",
    "                        min_row = row1.T\n",
    "            if(len(min_row) > 0):\n",
    "                aux = pd.concat([aux, min_row.T], ignore_index=False)\n",
    "            \n",
    "        # get the difference to remove the overlapinng bounding boxes\n",
    "        res = pd.concat([res_fil, aux.T]).drop_duplicates(keep=False)\n",
    "\n",
    "        # compute the input-format values\n",
    "        xmax = res.xmax.astype(float)\n",
    "        xmin = res.xmin.astype(float)\n",
    "        ymax = res.ymax.astype(float)\n",
    "        ymin = res.ymin.astype(float)\n",
    "\n",
    "        class_num = [0 if elem in CUPHEAD_CLASSES else 1 for elem in list(res[\"class\"].astype(int))]\n",
    "\n",
    "        x = list(((xmax+xmin)/2)/1920)\n",
    "        y = list(((ymax+ymin)/2)/1080)\n",
    "        w = list((xmax-xmin)/1920)\n",
    "        h = list((ymax-ymin)/1080)\n",
    "\n",
    "        return class_num, x, y, w, h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make detections on images and save labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'data/images/'\n",
    "DETECTIONS_PATH = 'data/detections/'\n",
    "LABELS_PATH = 'data/labels/'\n",
    "FILTER = 1\n",
    "\n",
    "\n",
    "for image in os.listdir(IMAGES_PATH):\n",
    "    # make detections on each image\n",
    "    img = os.path.join(IMAGES_PATH, image)\n",
    "    results = model(img)\n",
    "    \n",
    "    try:\n",
    "        class_num, x, y, w, h = filter(results, FILTER)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(str(img))\n",
    "        pass\n",
    "    \n",
    "    if(len(class_num) > 1):\n",
    "        cv2.imwrite(os.path.join(DETECTIONS_PATH,\"%s.jpg\" % os.path.splitext(image)[0]), np.squeeze(results.render())) # save detection frame as JPG file\n",
    "        with open(os.path.join(LABELS_PATH,\"%s.txt\" % os.path.splitext(image)[0]), 'w') as f: # create text file and write\n",
    "            for i in range(0, len(class_num)):\n",
    "                f.write(str(class_num[i])+\" {:.6f} {:.6f} {:.6f} {:.6f} \\n\".format(x[i], y[i], w[i], h[i]))\n",
    "    else:\n",
    "        os.remove(img) # remove the frames with no detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "690c9ea092c8a6fc9517542155c4d05fadb9e10c4733225e6f103cd30826cc12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
